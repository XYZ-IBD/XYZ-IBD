<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>XYZ-IBD</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <style>
        body {
            font-family: 'Open Sans', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            color: #2c3e50;
            font-size: 20px;
            background-color: #f8f9fa;
        }
        .container {
            max-width: 2200px;
            margin: 0 auto;
            padding: 40px 40px;
        }
        header {
            background-color: #2c3e50;
            background-image: url('images/header_bg.png');
            background-size: cover;
            background-position: center;
            color: white;
            padding: 2rem 0;
            text-align: center;
            position: relative;
            margin-bottom: 30px;
        }
        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(44, 62, 80, 0.8);
        }
        header .container {
            position: relative;
            z-index: 1;
        }
        header h1 {
            font-size: 4.5em;
            margin: 0;
            font-weight: 700;
            letter-spacing: -1px;
            text-shadow: 2px 2px 4px rgb(248, 241, 241);
        }
        header p {
            font-size: 2.2em;
            margin-top: 20px;
            line-height: 1.4;
            max-width: 1600px;
            margin-left: auto;
            margin-right: auto;
            text-shadow: 1px 1px 2px rgb(249, 249, 249);
        }
        header p .highlight {
            color: white;
            font-weight: 600;
        }
        .authors {
            font-family: 'Georgia', serif;
            font-size: 1.4em;
            margin-top: 30px;
            line-height: 1.6;
            text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5);
        }
        .authors .affiliation {
            font-size: 0.9em;
            font-style: italic;
            margin-top: 5px;
            color: rgba(255, 255, 255, 0.9);
        }
        h2 {
            color: #03528a;
            border-bottom: 3px solid #03528a;
            padding-bottom: 15px;
            margin-top: 60px;
            margin-bottom: 40px;
            font-size: 2.8em;
            text-align: center;
            font-weight: 700;
        }
        h3 {
            color: #03528a;
            font-size: 2em;
            margin-top: 50px;
            margin-bottom: 25px;
            font-weight: 600;
        }
        .section {
            margin: 60px 0;
            background-color: white;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 2px 15px rgba(0, 0, 0, 0.05);
        }
        .image-grid {
            display: flex;
            flex-direction: column;
            gap: 40px;
            margin: 30px 0;
        }
        .image-container {
            text-align: center;
            width: 100%;
        }
        .image-container img {
            width: 100%;
            height: auto;
            border-radius: 0;
            box-shadow: none;
            transition: transform 0.3s ease;
        }
        .image-container img:hover {
            transform: scale(1.01);
        }
        .bullet-points {
            list-style-type: none;
            padding-left: 0;
            margin-top: 30px;
            font-size: 1.4em;
            color: #2c3e50;
        }
        .bullet-points li {
            margin-bottom: 25px;
            position: relative;
            padding-left: 45px;
            line-height: 1.5;
        }
        .bullet-points li:before {
            content: "•";
            position: absolute;
            left: 0;
            font-size: 1.8em;
            top: -0.1em;
            line-height: 1;
            color: #03528a;
        }
        .highlight {
            font-weight: 600;
            color: #03528a;
        }
        .download-section {
            background-color: #f8f9fa;
            padding: 30px;
            border-radius: 12px;
            margin: 30px 0;
            border: 1px solid #e9ecef;
        }
        .citation {
            background-color: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            line-height: 1.6;
            white-space: pre-wrap;
            border: 1px solid #e9ecef;
            text-align: left;
        }
        .benchmark-links {
            list-style-type: none;
            padding-left: 0;
            margin-top: 25px;
            font-size: 1.3em;
        }
        .benchmark-links li {
            margin-bottom: 20px;
            position: relative;
            padding-left: 35px;
        }
        .benchmark-links li:before {
            content: "•";
            position: absolute;
            left: 0;
            font-size: 1.4em;
            top: -0.1em;
            line-height: 1;
            color: #03528a;
        }
        .benchmark-links a {
            color: #03528a;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        .benchmark-links a:hover {
            color: #088ff0;
            text-decoration: underline;
        }
        .social-links {
            margin-top: 30px;
            text-align: center;
        }
        .social-links a {
            color: white;
            font-size: 1.8em;
            margin: 0 20px;
            text-decoration: none;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
        }
        .social-links a:hover {
            color: #088ff0;
            transform: translateY(-2px);
        }
        .social-links span {
            font-size: 0.6em;
            vertical-align: middle;
            margin-left: 8px;
        }
        a {
            color: #03528a;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        a:hover {
            color: #088ff0;
        }
        p {
            font-size: 1.3em;
            line-height: 1.6;
            margin-bottom: 25px;
            color: #2c3e50;
        }
        .overview-paragraph {
            font-size: 1.8em;
            color: #555;
            font-weight: 400;
            margin-bottom: 30px;
        }
    </style>

</head>
<body>
    <header>
        <div class="container">
            <h1>XYZ-IBD</h1>
            <p><span class="highlight">A High-precision Bin-picking Dataset for Object 6D pose estimation and Monocular Depth Estimation Capturing Real-world Industrial Complexity</span></p>
            <div class="authors">
                Junwen Huang<sup>1,2</sup>, Jizhong Liang<sup>3,4</sup>, Jiaqi Hu<sup>1</sup>, Peter KT Yu<sup>1</sup>, Nassir Navab<sup>1,2</sup>, Benjamin Busam<sup>1,2</sup>
                <div class="affiliation">
                    <sup>1</sup>Technical University of Munich, <sup>2</sup>Munich Center for Machine Learning, 
                    <sup>3</sup>Shanghai Jiaotong University, <sup>4</sup>XYZ Robotics
                </div>
            </div>
            <div class="social-links">
                <a href="https://github.com/xyz-robotics/xyz-ibd" target="_blank">
                    <i class="fab fa-github"></i><span>GitHub</span>
                </a>
                <a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/tree/main" target="_blank" rel="noopener noreferrer">
                    <img
                        src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg"
                        alt="Hugging Face Logo"
                        width="40"
                        height="35"
                    ><span>HuggingFace</span>
                </a>
                <a href="https://arxiv.org/abs/2403.12345" target="_blank"><i class="fas fa-file-pdf"></i><span>Paper</span></a>
            </div>
        </div>
    </header>

    <div class="container">
        <section class="section">
            <h2>Overview</h2>
            <p class="overview-paragraph">
                The XYZ Industrial Bin Picking Dataset (XYZ-IBD) is a bin-picking dataset for <b>6D pose estimation</b> and <b>depth estimation</b>, capturing real-world industrial-grade complexity through <b>challenging geometries, materials, occlusions and clutter</b>. The dataset represents authentic robotic grasping scenarios with <b>millimeter-accurate annotations</b>.
            </p>

            <h3>Dataset Properties</h3>
            <ul class="bullet-points">
                <li><span class="highlight">Objects: </span> 15 highly-reflective industrial parts with various shapes and sizes (diameters ranging 5cm~30cm)</li>
                <li><span class="highlight">Scenes: </span> 75 scenes, 22k RGB/grayscale/depth imagesand 91k milimeter-level 6D pose annotations</li>
                <li><span class="highlight">Instances:</span>  24 instances per scene on average, with up to 60 instances in some scenes</li>
                <li><span class="highlight">Sensors:</span> 
                    XYZ Robotics DLP structured light, Photoneo PhoXi laser scanner, RealSense D415 stereo camera</li>
                <li><span class="highlight">Synthetic Data:</span> Realistic bin-picking scenes similated with BlenderProc, providing 50k+ synthetic training images</li>
            </ul><br>

            <h3>Scene Examples</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="images/teaser_v3.png" alt="Teaser Figure"> 
                </div>
            </div>
            <h3>Industrial Parts</h3>
            <div class="image-grid">
                <div class="image-container">
                    <img src="images/real_parts_ver.png" alt="Real industrial parts">
                </div>
            <h3>CAD Models</h3>
                <div class="image-container">
                    <img src="images/cad_ver.png" alt="CAD models of the industrial parts">
                </div>
            </div>
            <br>
            

            
        </section>

        <section class="section">
            <h2>Benchmarks & Challenges</h2>
                <h3>Model-based Object 6D Pose Estimation</h3>
                <p>
                    The XYZ-IBD dataset is part of the Benchmark for 6D Object Pose Estimation (BOP) and serves as one of the official BOP-Industrial datasets for the BOP Challenge 2025. 
                    The XYZ-IBD dataset is evaluated on model-based 2D and 6D object detection tasks, following the BOP Challenge 2025 metrics and is hosted on the official BOP-Industrial Leaderboard. 
                    The challenge will also be featured at the ICCV 2025 R6D Workshop. 
                </p>
                <ul class="benchmark-links">
                    <li><a href="https://bop.felk.cvut.cz/challenges/">BOP Challenge 2025 Metrics</a></li>
                    <li><a href="https://bop.felk.cvut.cz/leaderboards/pose-detection-unseen-bop24/bop-industrial/">BOP-Industrial Leaderboard</a></li>
                    <li><a href="https://cmp.felk.cvut.cz/sixd/workshop_2024/">ICCV 2025 R6D Workshop</a></li>
                </ul>

            <h3>Monocular Depth Estimation</h3>
            <p>
                The XYZ-IBD dataset is also associated with the <b>Transparent & Reflective Objects In the Wild Challenges (TRICKY)</b> for the Monocular Depth Estimation task. 
                Evaluation on XYZ-IBD for this task follows the TRICKY 2025 metrics and is hosted on the official TRICKY 2025 Leaderboard, which will be featured as part of the TRICKY Workshop at ICCV 2025.
            </p>
            <ul class="benchmark-links">
                <li><a href="https://cvlab-unibo.github.io/booster-web/tricky24.html">TRICKY challenge 2025 Metrics</a></li>
                <li><a href="https://cvlab-unibo.github.io/booster-web/benchmark.html">TRICKY Leaderboard</a></li>
                <li><a href="https://cvlab-unibo.github.io/booster-web/tricky24.html">ICCV 2025 TRICKY Workshop</a></li>
            </ul>
            
        </section> 

        
        <section class="section">
            <h2>Download</h2>
            <div class="download-section">
                <p>The pose estimation dataset is available for download at the following links. You can also find the dataset in both the <a href="https://bop.felk.cvut.cz/datasets/">BOP</a> website or <a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/tree/main">HuggingFace</a>.</p>
                <h3>Object 6D Pose Estimation</h3>
                <ul class="benchmark-links">
                    <li>PBR-BlenderProc BOP format training images <a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/resolve/main/xyzibd_train_pbr.zip">[Part 1]</a>
                    <a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/resolve/main/xyzibd_train_pbr_part2.zip">[Part 2]</a> </li>
                    <li><a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/resolve/main/xyzibd_val.zip">Validation Data</a></li>
                    <li><a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/resolve/main/xyzibd_test_all.zip">Testing Data</a></li>
                    <li><a href="https://huggingface.co/datasets/bop-benchmark/xyzibd/resolve/main/xyzibd_models.zip">Object Models</a></li>
                </ul>
                <h3>Depth Estimation</h3>
                <p>The depth estimation dataset is available for download at the following links. You can also find the dataset in the <a href="https://cvlab-unibo.github.io/booster-web/tricky24.html">TRICKY</a> website.</p>
                <ul class="benchmark-links">
                    <li><a href="https://cvlab-unibo.github.io/booster-web/tricky24.html">Training Data (Synthetic and Real)</a></li>
                    <li><a href="https://cvlab-unibo.github.io/booster-web/benchmark.html">Validation Data</a></li>
                    <li><a href="https://cvlab-unibo.github.io/booster-web/benchmark.html">Testing Data</a></li>
                </ul>
            </div>
        </section>

        <section class="section">
            <h3>Citation & License</h3>
            <p>
                If you find this dataset helpful, please cite the following paper:
            </p>
            <div class="citation">
                @inproceedings{xyz_ibd_2024,
                    title={XYZ Industrial Bin Picking Dataset: A Comprehensive Dataset for Industrial Object Pose Estimation},
                    author={Your Name and Co-authors},
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
                    year={2024}
                }
            </div>
            <p>
                XYZ-IBD is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> license.<br>
                <b>Custom license available upon request</b>, if you are interested in using the dataset for commercial purposes, please contact us.
            </p>
        </section>

        <section class="section">
            <h3>Contact</h3>
            <p>
                For any questions or issues regarding the dataset, please contact:<br>
                <a href="mailto:junwen.huang@tum.de">junwen.huang@tum.de</a>, <br>
                <a href="mailto:peter.yu@xyzrobotics.com">peter.yu@xyzrobotics.com</a>
            </p>
        </section>
    </div>
</body>
</html>
